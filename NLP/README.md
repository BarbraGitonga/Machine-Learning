# Natural Language Processing with Disaster Tweets

## Overview

This is the Kaggle chellenge on being able to identify if a tweet is talking about a real disaster or a fake disaster.
The accuracy score of this notebook is 0.82960  and this is the highest score I have gotten so far.
The model used is `google-bert/bert-base-uncased` which is a pretained transformer model that I have finetuned to the data provided by kaggle for this competition and only the data provided by Kaggle.

## Competition

[Kaggle competition]("https://www.kaggle.com/competitions/nlp-getting-started/overview") - This is the link to acccess the kaggle competition.